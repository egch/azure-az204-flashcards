# Azure webapps

### Powershell
```powershell
$gitrepo="https://github.com/Azure-Samples/app-service-web-dotnet-get-started.git"
$webappname="mywebapp$(Get-Random)"
$location="West Europe"

# Create a resource group.
New-AzResourceGroup -Name myResourceGroup -Location $location

# Create an App Service plan in Free tier.
New-AzAppServicePlan -Name $webappname -Location $location -ResourceGroupName myResourceGroup -Tier Free

# Create a web app.
New-AzWebApp -Name $webappname -Location $location -AppServicePlan $webappname 
	-ResourceGroupName myResourceGroup

# Configure GitHub deployment from your GitHub repo and deploy once.
$PropertiesObject = @{
    repoUrl = "$gitrepo";
    branch = "master";
    isManualIntegration = "true";
}
Set-AzResource -Properties $PropertiesObject -ResourceGroupName myResourceGroup 
	-ResourceType Microsoft.Web/sites/sourcecontrols -ResourceName $webappname/web 
	-ApiVersion 2015-08-01 -Force
```

### CLI
```bash
#!/bin/bash

gitrepo=<replace-with-URL-of-your-own-GitHub-repo>
token=<replace-with-a-GitHub-access-token>
webappname=mywebapp$RANDOM

# Create a resource group.
az group create --location westeurope --name myResourceGroup

# Create an App Service plan in `FREE` tier.
az appservice plan create --name $webappname --resource-group myResourceGroup --sku FREE

# Create a web app.
az webapp create --name $webappname --resource-group myResourceGroup --plan $webappname

# Configure continuous deployment from GitHub. 
# --git-token parameter is required only once per Azure account (Azure remembers token).
az webapp deployment source config --name $webappname --resource-group myResourceGroup \
--repo-url $gitrepo --branch master --git-token $token

# Configure logging for a web app. (autogenerated)
az webapp log config --name MyWebapp --resource-group MyResourceGroup --web-server-logging off
# Add allowed origins.
az webapp cors add --allowed-origins
                   [--ids]
                   [--name]
                   [--resource-group]
                   [--slot]
                   [--subscription]

# Copy the result of the following command into a browser to see the web app.
echo http://$webappname.azurewebsites.net
```

### Azure Container Groups - secrets

```yaml
apiVersion: '2018-10-01'
location: eastus
name: mycontainernew
properties:
  containers:
  - name: dotnetappnew
    properties:
      image: demoregistry3000.azurecr.io/dotnetapp
      resources:
        requests:
          cpu: 1
          memoryInGb: 1.5
      volumeMounts:
      - mountPath: /mounts/secrets
        name: volumesecret
  osType: Linux
  imageRegistryCredentials:
    - server: demoregistry3000.azurecr.io
      username: demoregistry3000
      password: RP+e8rd6ZDGMK2cKZODtFhNtM8jFm8im
  volumes:
  - name: volumesecret
    secret:
      storage-connection: RGVmYXVsdEVuZHBvaW50c1Byb3RvY29sPWh0dHBzO0FjY291bnROYW1lPWRlbW9zdG9yZTQwMDAwO0FjY291bnRLZXk9b0tTVXNtKzVIc3lJVnhPUlFBWm9XcVl2eE9WUjgxRjNaQ293ck5lL2dVdlZsNDA5cThFMlRNUXRabHljdU45ZkkvT3hWQnUvcUtEaE5OU1FkMDlMWnc9PTtFbmRwb2ludFN1ZmZpeD1jb3JlLndpbmRvd3MubmV0
tags: null
type: Microsoft.ContainerInstance/containerGroups
```

# ARM templates

```json
{
    "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "storageCount": {
            "type": "int",
            "defaultValue": 2
        }
    },
    "resources": [
        {
            "type": "Microsoft.Storage/storageAccounts",
            "apiVersion": "2019-04-01",
            "name": "[concat(copyIndex(),'storage80808')]",
            "location": "[resourceGroup().location]",
            "sku": {
                "name": "Standard_LRS"
            },
            "kind": "StorageV2",
            "properties": {},
            "copy": {
                "name": "storagecopy",
                "count": "[parameters('storageCount')]"
            }
        }
    ],
    "outputs": {}
}
```
## Scenario
1. Export a Resource Manager template.
2. Modify the template by changing the storage account name and region.
3. Create a new template deployment.
4. Deploy the template to create a new storage account in the target region.
5. Use AZCopy to copy the data to the new storage account.


# Function Apps

### .NET

```c#
public static class Function1
{
	[FunctionName("QueueTable")]
	// The ICollector interface is to write multiple to the output
	public static void Run([QueueTrigger("appqueue", Connection = "storage_connection")]JObject myQueueItem, 
	    [Table("Customer", Connection = "storage_connection")]ICollector<Customer> outputTable,
	    [Queue("newqueue", Connection = "storage_connection")]ICollector<Customer> outputQueue,
	    [Blob("data/{rand-guid}", FileAccess.Write,Connection = "storage_connection")] TextWriter blobOutput,
	    ILogger log)
	{
	    log.LogInformation("Adding Customer");
	    Customer obj = new Customer();
	    obj.PartitionKey= myQueueItem["Id"].ToString();
	    obj.RowKey=myQueueItem["Quantity"].ToString();
	    outputTable.Add(obj); // Use ICollector<T>
	    outputQueue.Add(obj); // The output can be an object serializable as JSON, string, byte[] and CloudQueueMessage
	    blobOutput.Write($"Partition Key {obj.PartitionKey}");
	    // For blob, you have an output of Stream, string, CloudBlockBlob
	}
}
```
## Function files
Specfic to each function:
- run.csx
- function.json

The function app defines another file: _host.json_.

```json
// host json
{
    "version": "2.0",
    "extensions": {
        "queues": {
            "maxPollingInterval": "00:00:02",
            "visibilityTimeout" : "00:00:30",
            "batchSize": 16,
            "maxDequeueCount": 5,
            "newBatchThreshold": 8,
            "messageEncoding": "base64"
        }
    }
```
### function.json
```json
{
  "bindings": [
    {
      "direction": "in",
      "type": "queueTrigger",
      "connection": "demotore4000_STORAGE",
      "name": "queueitem",
      "queueName": "appqueue"
    },
    {
      "type": "table",
      "name": "$return",
      "tableName": "customer",
      "connection": "demotore4000_STORAGE",
      "direction": "out"
    }
  ],
  "disabled": false
}
```
## Authorization level
- function
- anonymous
- admin


# Appinsights - Telemetry

```c#
public class MyTelemetry : ITelemetryInitializer
{
private IHttpContextAccessor _context;

public MyTelemetry(IHttpContextAccessor httpContextAccessor)
{
    _context = httpContextAccessor ?? throw new ArgumentNullException("httpContextAccessor");
}

public void Initialize(ITelemetry telemetry)
{
    var current = _context.HttpContext;
    if (current != null)
    {
	if (current.Request.Headers.ContainsKey("UserId"))
	{
	    telemetry.Context.User.Id = current.Request.Headers["UserId"].ToString();
	    telemetry.Context.Session.Id = telemetry.Context.User.Id;
	    telemetry.Context.User.AuthenticatedUserId = telemetry.Context.User.Id;
	}
	else
	    telemetry.Context.User.Id = "1";
    }
}
}
```


# Event Grid

### Schema

```js
[
  {
    "topic": string,
    "subject": string,
    "id": string,
    "eventType": string,
    "eventTime": string,
    "data":{
      object-unique-to-each-publisher
    },
    "dataVersion": string,
    "metadataVersion": string
  }
]
```

E.g.

```json
[
  {
    "topic": "/subscriptions/{subscription-id}/resourceGroups/Storage/providers/Microsoft.Storage/storageAccounts/xstoretestaccount",
    "subject": "/blobServices/default/containers/oc2d2817345i200097container/blobs/oc2d2817345i20002296blob",
    "eventType": "Microsoft.Storage.BlobCreated",
    "eventTime": "2017-06-26T18:41:00.9584103Z",
    "id": "831e1650-001e-001b-66ab-eeb76e069631",
    "data": {
      "api": "PutBlockList",
      "clientRequestId": "6d79dbfb-0e37-4fc4-981f-442c9ca65760",
      "requestId": "831e1650-001e-001b-66ab-eeb76e000000",
      "eTag": "0x8D4BCC2E4835CD0",
      "contentType": "application/octet-stream",
      "contentLength": 524288,
      "blobType": "BlockBlob",
      "url": "https://oc2d2817345i60006.blob.core.windows.net/oc2d2817345i200097container/oc2d2817345i20002296blob",
      "sequencer": "00000000000004420000000000028963",
      "storageDiagnostics": {
        "batchId": "b68529f3-68cd-4744-baa4-3c0498ec19f0"
      }
    },
    "dataVersion": "",
    "metadataVersion": "1"
  }
]
```

### CLI

```bash
az eventgrid event-subscription create --name queue-subscription 
	--source-resource-id /subscriptions/20c6eec9-2d80-4700-b0f6-4fde579a8783/resourceGroups/demogrp1/providers/
		Microsoft.Storage/storageAccounts/demostore4000 
	--endpoint-type servicebusqueue 
	--endpoint /subscriptions/20c6eec9-2d80-4700-b0f6-4fde579a8783/resourceGroups/demogrp1/providers/
		Microsoft.ServiceBus/namespaces/appnamespace4000/queues/appqueue
```
# EventHub

### Send

```c#
private static async Task SendData()
{
    EventHubProducerClient client = new EventHubProducerClient(connstring, hubname);

    foreach (DataRow row in dt_table.Rows)
    {
	ActivityData obj = new ActivityData();
	obj.Correlationid = row[0].ToString();
	obj.Operationname = row[1].ToString();
	obj.status = row[2].ToString();
	obj.EventCategory = row[3].ToString();
	obj.Level = row[4].ToString();
	obj.dttime = DateTime.Parse(row[5].ToString());
	obj.subscription = row[6].ToString();
	obj.InitiatedBy = row[7].ToString();
	obj.resourcetype = row[8].ToString();
	obj.resourcegroup = row[9].ToString();
	obj.resource = row[10].ToString();
	obj.id = Guid.NewGuid().ToString();

	using EventDataBatch batch_obj = await client.CreateBatchAsync();
	batch_obj.TryAdd(new EventData(Encoding.UTF8.GetBytes(obj.ToString())));
	await client.SendAsync(batch_obj);

	Console.WriteLine("Sending Data {0}", obj.id);

    }
}
```

### Receive

```c#
static private async Task GetEvents()
{
    EventHubConsumerClient client = new EventHubConsumerClient("$Default", connstring, hubname);

    string _partition = (await client.GetPartitionIdsAsync()).First();

    var cancellation = new CancellationToken();

    EventPosition _position = EventPosition.FromSequenceNumber(40);
    Console.WriteLine("Getting events from a certain position from a particular partition");
    await foreach (PartitionEvent _recent_event in client.ReadEventsFromPartitionAsync(_partition, _position, cancellation))
    {                
	EventData event_data = _recent_event.Data;               

	Console.WriteLine(Encoding.UTF8.GetString(event_data.Body.ToArray()));
	Console.WriteLine($"Sequence Number : {event_data.SequenceNumber}");


    }

}
```

### Powershell
```powershell
New-AzResourceGroup –Name myResourceGroup –Location eastus
New-AzEventHubNamespace -ResourceGroupName myResourceGroup -NamespaceName namespace_name -Location eastus
New-AzEventHub -ResourceGroupName myResourceGroup -NamespaceName namespace_name -EventHubName eventhub_name -MessageRetentionInDays 3
```

### CLI

```bash
az group create --name <resource group name> --location eastus
az eventhubs namespace create --name <Event Hubs namespace> --resource-group <resource group name> -l <region, for example: East US>
az eventhubs eventhub create --name <event hub name> --resource-group <resource group name> --namespace-name <Event Hubs namespace>
# Getting the connection string
az eventhubs eventhub authorization-rule keys list --resource-group MYRESOURCEGROUP --namespace-name MYEHUBNAMESPACE --eventhub-name MYEHUB --name RootManageSharedAccessKey
```

# Redis

### .NET

```c#
static void Main(string[] args)
{
    IDatabase l_cache = redisconn.Value.GetDatabase();
    //Set a value in the redis database
    //l_cache.StringSet("AvgOrders", "120");

    // If you want to set an expiration for the keys
    //l_cache.KeyExpire("AvgOrders", new TimeSpan(0, 0, 30));


    // To delete a key
    //l_cache.KeyDelete("AvgOrders");

    //Console.WriteLine("The Average Daily Orders are " + l_cache.StringGet("AvgOrders"));

    // You can also work with class objects
    // Add the object to the cache
    Customer obj = new Customer(10, "userA");
    l_cache.StringSet("obj1", JsonConvert.SerializeObject(obj));

    // Get the object from the cache
    Customer newobj = JsonConvert.DeserializeObject<Customer>(l_cache.StringGet("obj1"));
    Console.WriteLine("The Customer ID is " + newobj.customerID);
    Console.WriteLine("The Customer Name is " + newobj.customerName);

    redisconn.Value.Dispose();
    Console.ReadKey();
}

// The connection to Azure Cache for Redis is managed via the ConenctionMultiplexer class
private static Lazy<ConnectionMultiplexer> redisconn = new Lazy<ConnectionMultiplexer>(() =>
{
    string str_conn = "democache2020.redis.cache.windows.net:6380,password=mJsaC+eCyoqfkvDFlFY6383FU7QaCnCdV5vMOhEsXMA=,ssl=True,abortConnect=False";
    return ConnectionMultiplexer.Connect(str_conn);
});

public static ConnectionMultiplexer Connection
{
    get
    {
	return redisconn.Value;
    }
}
```
### CLI
```shell
az redis list-keys 
```




# AKS - Manage Azure Kubernetes Services

### Script

```bash
// Here we will create a new resource group
az group create --name kubernetesgrp --location eastus

// Then we will create a new Kubernetes cluster
az aks create --resource-group kubernetesgrp --name democluster --node-count 1 --enable-addons monitoring --generate-ssh-keys

// We will then install the kubectl tool
az aks install-cli --install-location=./kubectl

// This allows kubectl to connect to the Kubernetes cluster
az aks get-credentials --resource-group kubernetesgrp --name democluster 

```
# CDN - Control Azure CDN caching behavior with caching rules
## Caching behavior settings
- Bypass cache: Do not cache and ignore origin-provided cache-directive headers.

- Override: Ignore origin-provided cache duration; use the provided cache duration instead. This will not override cache-control: no-cache.

- Set if missing: Honor origin-provided cache-directive headers, if they exist; otherwise, use the provided cache duration.

## CDN caching behavior with query strings
- **Ignore query strings**: Default mode. In this mode, the CDN point-of-presence (POP) node passes the query strings from the requestor to the origin server on the first request and caches the asset. All subsequent requests for the asset that are served from the POP ignore the query strings until the cached asset expires.

- **Bypass caching for query strings**: In this mode, requests with query strings are not cached at the CDN POP node. The POP node retrieves the asset directly from the origin server and passes it to the requestor with each request.

- **Cache every unique URL**: In this mode, each request with a unique URL, including the query string, is treated as a unique asset with its own cache. For example, the response from the origin server for a request for example.ashx?q=test1 is cached at the POP node and returned for subsequent caches with the same query string. A request for example.ashx?q=test2 is cached as a separate asset with its own time-to-live setting.

# Container
## CLI
```bash
# Deploy with YAML template
az container create --resource-group myResourceGroup --file deploy-aci.yaml

#Attach local standard output and error streams to a container in a container group.
az container attach [--container-name]
                    [--ids]
                    [--name]
                    [--resource-group]
                    [--subscription]
az container logs --resource-group myResourceGroup --name mycontainer

```
# azCopy
```bash
// To create a container
azcopy make "https://azcopysource1000.blob.core.windows.net/data?sv=2020-02-10&ss=b&srt=sco&sp=rwlac&se=2021-04-12T22:13:45Z&st=2021-04-12T14:13:45Z&spr=https&sig=SJxLBBaPQ3uqm48ds3b36K%2BOX9KfrtYjgScl89aNDoI%3D"

// To upload a directory and subdirectories to a directory in the container

azcopy copy "newdir/*" "https://azcopysource1000.blob.core.windows.net/data/newdir?sv=2020-02-10&ss=b&srt=sco&sp=rwlac&se=2021-04-12T22:13:45Z&st=2021-04-12T14:13:45Z&spr=https&sig=SJxLBBaPQ3uqm48ds3b36K%2BOX9KfrtYjgScl89aNDoI%3D" --recursive

```

